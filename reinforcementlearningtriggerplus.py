# -*- coding: utf-8 -*-
"""ReinforcementLearningTriggerPlus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Okb5Ay32KVZvfWc_sjoJdXSWW8V7Sj7D

Initialize google authentications
"""

from google.colab import auth
import google.auth
auth.authenticate_user()
!pip install alpaca-trade-api==0.49.1
!pip install google-cloud-secret-manager==1.0.0
!pip install google-cloud-pubsub

# # secret manager validation
from google.cloud import secretmanager
import json
import alpaca_trade_api as tradeapi
import time

# secret_id  = '96ab17e2'
# project_id = 'stock-analysis-274918'
# client  = secretmanager.SecretManagerServiceClient()
# id_name = client.secret_version_path(project_id, secret_id, "latest")

# # Access the secret version.
# id_response = client.access_secret_version(id_name)

# keys_dict = json.loads(id_response.payload.data.decode("utf-8"))
APCA_API_KEY_ID = "<KEY_ID>" #keys_dict['api_key_paper']
APCA_API_SECRET_KEY = "<SECRET_KEY>" #keys_dict['secret_key_paper']
# validate API
api = tradeapi.REST(APCA_API_KEY_ID, APCA_API_SECRET_KEY, 'https://paper-api.alpaca.markets')

target_stock = ['GS', 'C']
time_scale   = 'minute'
begin_timestamp = "2021-02-19T9:00:00-04:00" #"2021-02-19T9:00:00-04:00"
last_train_timestamp = "2021-03-05T16:00:00-04:00"

# get training data, format into 'ds' and 'y' columns
combo_data_ret = None
while True:
    print(last_train_timestamp)
    data = api.get_barset(target_stock, time_scale, 
                                until = last_train_timestamp,
                                limit = 1000)
    GS_data = data.df['GS'].tz_convert("utc")[['close', 'volume']]
    GS_data.columns = ["GS.close", "GS.volume"]
    GS_data = GS_data[GS_data["GS.close"] > 0]
    C_data = data.df['C'].tz_convert("utc")[['close', 'volume']]
    C_data.columns = ["C.close", "C.volume"]
    C_data = C_data[C_data["C.close"] > 0]
    GS_data["datetime"] = GS_data.index
    C_data["datetime"] = C_data.index

    combo_data = GS_data.merge(C_data, on="datetime", how="inner")
    combo_data = combo_data.dropna()
    if combo_data_ret is None:
        combo_data_ret = combo_data
    else:
        combo_data_ret = combo_data.append(combo_data_ret, ignore_index=True)
    if last_train_timestamp > begin_timestamp:
        last_train_timestamp = combo_data_ret.datetime.iloc[0].isoformat().replace("+00:00", "-04:00")
    else:
        break
combo_data = combo_data_ret.drop_duplicates(subset="datetime")

import numpy as np

df = data.df['GS'].tz_convert("utc")
ts = df.index[10]
idx = df.index.get_loc(ts)
print(idx)
df.iloc[(idx-10):idx].close

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from tqdm import tqdm
import torch.optim as optim
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime

price = -np.array(combo_data["C.close"]) + 0.2385 * np.array(combo_data["GS.close"])
volume1 = np.array(combo_data["C.volume"])
volume2 = np.array(combo_data["GS.volume"])
df = pd.DataFrame.from_dict({"price1": np.array(combo_data["C.close"]), "price2": np.array(combo_data["GS.close"]), 
                             "volume1": volume1, "volume2": volume2, "datetime": combo_data["datetime"],
                             "price": price})
df.head()

plt.plot(price)
plt.axhline(y=np.mean(price), color="red")
plt.show()

def visualize_ma_distribution(df, moving_len):
    df["MA"] = df["price"].rolling(moving_len).mean()
    df["VOL"] = df["price"].rolling(moving_len).std()
    price_lst = (np.array(df["price"]) - np.array(df["MA"])) / np.array(df["VOL"])
    price_lst = price_lst[~np.isnan(price_lst)]

    plt.hist(price_lst, bins=100)
    plt.title("Distribution of normalized price when window size = " + str(moving_len))
    plt.show()

    plt.plot(price_lst)
    plt.show()

visualize_ma_distribution(df, 7)

from sklearn.linear_model import LinearRegression
import time

class Net(nn.Module):
    def __init__(self, INPUT_DIM, HIDDEN_DIM_LST, ACTIVATION_FUNC, OUTPUT_DIM=1, NO_TRADE_REGION=0.1):
        super(Net, self).__init__()
        self.layer_lst = nn.ModuleList()
        self.bn = nn.ModuleList()
        self.activation_functions = ACTIVATION_FUNC
        self.no_trade = NO_TRADE_REGION

        self.layer_lst.append(nn.Linear(INPUT_DIM, HIDDEN_DIM_LST[0]))
        #self.bn.append(nn.BatchNorm1d(HIDDEN_DIM_LST[0],momentum=0.1))
        for i in range(1, len(HIDDEN_DIM_LST)):
            self.layer_lst.append(nn.Linear(HIDDEN_DIM_LST[i - 1], HIDDEN_DIM_LST[i]))
            #self.bn.append(nn.BatchNorm1d(HIDDEN_DIM_LST[i], momentum=0.1))
        self.layer_lst.append(nn.Linear(HIDDEN_DIM_LST[-1], OUTPUT_DIM))
        self.ratio_lst = [1]
    
    def compute_ratio(self, price_lst):        
        y = np.array(price_lst[0])
        X = np.array(price_lst[1:]).T
        reg = LinearRegression().fit(X, y)
        coef = [1] + list(-reg.coef_)
        if reg.intercept_ < 0:
            coef = list(-np.array(coef))
        self.ratio_lst = coef
    
    def get_comb_price(self, price_lst):
        comb_price = self.ratio_lst[0] * np.array(price_lst[0])
        for i in range(1, len(price_lst)):
            comb_price += self.ratio_lst[i] * np.array(price_lst[i])
        return comb_price

    def forward(self, x):
        for i in range(len(self.layer_lst) - 1):
            x = self.layer_lst[i](x)
            #x = self.bn[i](x)
            func = self.activation_functions[i]
            if func == "relu":
                x = F.relu(x)
            elif func == "sigmoid":
                x = torch.sigmoid(x)
            else:
                x = torch.tanh(x)
        x = self.layer_lst[-1](x)
        signal = torch.tanh(x) #torch.softmax(x, 1) @ torch.tensor([1., 0]).reshape((2, 1))
        # if abs(signal) <= self.no_trade:
        #     signal = signal * 0
        strong_signal = torch.abs(signal) > self.no_trade
        signal = signal * strong_signal
        return signal

def prepare_model(hidden_lst, activation_functions, lr, decay, scheduler_step, no_trade):
    model = Net(2, hidden_lst, activation_functions, 1, no_trade)
    optimizer = optim.SGD(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=decay)
    return model, optimizer, scheduler

def trade(model, df, cash=100, moving_len=30, start_idx=0, training=False, optimizer=None, scheduler=None):
    cash_arr = [cash]
    equity_arr = [0]

    df = df.copy()

    curr_cash = torch.tensor([cash]).float()
    curr_equity = torch.tensor([0]).float()
    df["MA"] = df["price"].rolling(moving_len).mean()
    df["MA_diff"] = df["MA"].pct_change()
    df["VOL"] = df["price"].rolling(moving_len).std()
    vol_all = df["price"].std()
    mu_all = df["price"].mean()

    start_idx = max(start_idx, moving_len + 1)

    size = df.shape[0] - start_idx

    cash_lst = torch.zeros(size + 1).float()
    equity_lst = torch.zeros(size + 1).float()
    portfolio_lst = torch.zeros(size + 1).float()
    cash_lst[0] = cash
    portfolio_lst[0] = cash
    change_lst = torch.zeros(size).float()
    signal_lst = torch.zeros(size).float()

    df["adj_price"] = (df.price - df.MA) / df.VOL
    #x = torch.tensor(list(df.iloc[start_idx:]["adj_price"])).reshape((-1,1))
    # x = torch.from_numpy(np.array(df.iloc[start_idx:][["adj_price", "MA_diff"]])).float()
    # signal_lst = model(x).reshape((-1,))
    # prev_portfolio = curr_cash + curr_equity
    curr_cash = cash
    curr_equity = 0
    curr_portfolio = float(curr_cash + curr_equity)
    shares_lst = []

    for i in tqdm(range(start_idx, df.shape[0])):
        price = float(df.iloc[i]["price"])
        prev_price = float(df.iloc[i-1]["price"])
        # volume1 = float(df.iloc[i]["volume1"])
        # volume2 = float(df.iloc[i]["volume2"])
        # ma = float(df.iloc[i-1]["MA"]) #np.mean(df.iloc[(i-moving_len):i]["price"])
        # vol = float(df.iloc[i-1]["VOL"]) #np.std(df.iloc[(i-moving_len):i]["price"])
        # adj_price = (price - ma) / vol # price #(price - mu_all) / vol_all #(price - ma) / vol
        # data = torch.tensor([[adj_price]]) #torch.tensor([[adj_price, volume1, volume2]])
        # signal = model(data).reshape((-1,))
        # signal = signal_lst[i - start_idx]
        #curr_equity *= price / prev_price
        curr_idx = i - start_idx
        # curr_equity = price / prev_price * equity_lst[curr_idx].clone()

        adj_price = float(df.iloc[i]["adj_price"])
        ma_diff = float(df.iloc[i]["MA_diff"])
        data = torch.tensor([[adj_price, ma_diff]]) #torch.tensor([[adj_price, volume1, volume2]])

        if training:
            optimizer.zero_grad()

        signal = model(data).reshape((-1,))[0]
        signal_lst[curr_idx] = signal

        if signal < 0:
            change = (price / prev_price * curr_equity + 0.5*cash) * torch.abs(signal) #(curr_equity.clone() + 0.5*cash) * torch.abs(signal)
            # curr_cash += change
            # curr_equity -= change
            change_lst[curr_idx] = change
            new_cash = curr_cash + change
            cash_lst[curr_idx + 1] = new_cash
            new_equity = price / prev_price * curr_equity - change
            equity_lst[curr_idx + 1] = new_equity
        else:
            change = curr_cash * torch.abs(signal) #curr_cash.clone() * torch.abs(signal)
            # curr_cash -= change
            # curr_equity += change
            change_lst[curr_idx] = change
            new_cash = curr_cash - change
            cash_lst[curr_idx + 1] = new_cash
            new_equity = price / prev_price * curr_equity + change
            equity_lst[curr_idx + 1] = new_equity
        
        shares = change / price
        shares_lst.append(float(shares.data))
        # else:
        #     new_cash = curr_cash
        #     new_equity = curr_equity

        new_portfolio = new_cash + new_equity
        portfolio_lst[curr_idx + 1] = new_portfolio

        loss = 1 - new_portfolio / curr_portfolio

        if torch.isnan(loss.data):
            break

        if training:
            loss.backward()
            optimizer.step()
            scheduler.step()
        
        # loss = cash - curr_cash - curr_equity
        # loss.backward()

        # assert 1 == 0
        curr_cash = float(new_cash.data)
        curr_equity = float(new_equity.data)
        curr_portfolio = float(new_portfolio.data)

        cash_arr.append(curr_cash)
        equity_arr.append(curr_equity)

    profit = curr_cash + curr_equity - cash
    if training:
        return cash_arr, equity_arr, profit, model, optimizer, scheduler
    else:
        return cash_arr, equity_arr, profit, shares_lst

def train(df, epoch=100, hidden_lst = [50], activations=["relu"], lr=1e-1, decay=1, 
          scheduler_step=100, cash=100, moving_len=30, no_trade=0.1):
    torch.manual_seed(0)
    model, optimizer, scheduler = prepare_model(hidden_lst, activations, lr, decay, scheduler_step, no_trade)

    df = df.copy()
    model.compute_ratio([np.array(df["price1"]), np.array(df["price2"])])
    print(model.ratio_lst)
    time.sleep(1)
    df["price"] = model.get_comb_price([np.array(df["price1"]), np.array(df["price2"])])

    model.train()
    profit_arr = []
    for i in range(epoch):
        print("Epoch #" + str(i + 1) + ":")
        time.sleep(1)
        # optimizer.zero_grad()

        cash_arr, equity_arr, profit, model, optimizer, scheduler = trade(model, df, cash=cash, moving_len=moving_len, 
                                             training=True, optimizer=optimizer, scheduler=scheduler)
        # loss = -profit
        # loss.backward()
        profit_arr.append(float(profit))

        # if torch.isnan(loss.data):
        #     break
        # optimizer.step()
        # scheduler.step()
        plt.plot(np.array(cash_arr) + np.array(equity_arr))
        plt.title("Profit = " + str(profit))
        plt.show()

        plt.plot(np.array(cash_arr))
        plt.title("Cash Value Over Time")
        plt.show()

    return model, profit_arr

def test(model, df, train_idx, cash=100, moving_len=30):
    model.eval()
    df["price"] = model.get_comb_price([np.array(df["price1"]), np.array(df["price2"])])
    cash_arr, equity_arr, profit, shares_lst = trade(model, df, cash=cash, moving_len=moving_len, start_idx=train_idx)
    return cash_arr, equity_arr, float(profit), np.sum(shares_lst)

N = df.shape[0]
train_idx = int(N * 0.8)
moving_len = 30
no_trade=0.01

model, profit_arr = train(df.iloc[:train_idx], epoch=2, hidden_lst = [50, 50], 
                          activations=["tanh", "tanh"], 
                          lr=1e-3, decay=1, scheduler_step=200, cash=100, moving_len=moving_len, no_trade=no_trade)
df["price"] = model.get_comb_price([np.array(df["price1"]), np.array(df["price2"])])
cash_arr, equity_arr, profit, total_shares = test(model, df, train_idx, cash=100, moving_len=moving_len)

bid_ask_loss = total_shares * (0.017 * abs(model.ratio_lst[0]) + 0.141 * abs(model.ratio_lst[1]))
C_increase = df["price1"].iloc[-1] / df["price1"].iloc[train_idx] - 1
GS_increase = df["price2"].iloc[-1] / df["price2"].iloc[train_idx] - 1

# plt.plot(profit_arr)
# plt.title("Final Profit = " + str(profit_arr[-1]))
# plt.show()

#plt.plot(cash_arr, label="Cash")
#plt.plot(equity_arr, label="Equity")
plt.plot(np.array(cash_arr) + np.array(equity_arr), label="Portfolio")
plt.legend()
plt.title("Trading Performance on Test Data\nProfit = " + str(profit) + "\nC: " + str(C_increase) + "\nGS: " + str(GS_increase))
plt.show()

plt.plot(cash_arr)
plt.title("Cash Values on Test Data\nTotal Shares Traded = " + str(total_shares) + "\nBid & Ask Loss = " + str(bid_ask_loss))
plt.show()

end = df.shape[0] - train_idx
vbar = 27
plt.plot(cash_arr[:end])
plt.axvline(x = vbar, color="red")
plt.title("Cash Values on Test Data")
plt.show()

df_cp = df.copy()
moving_len = 7
df_cp["MA"] = df_cp["price"].rolling(moving_len).mean()
df_cp["VOL"] = df_cp["price"].rolling(moving_len).std()
df_cp["Adj_Price"] = (np.array(df_cp["price"]) - np.array(df_cp["MA"])) / np.array(df_cp["VOL"])
price_lst = np.array(df_cp.iloc[train_idx:(train_idx + end)]["Adj_Price"])
plt.plot(price_lst)
plt.axvline(x = vbar, color="red")
plt.title("Price on Test Data")
plt.show()
